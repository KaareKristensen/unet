{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "from PIL import Image\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:/Users/Kaare/Documents/Git projects/unet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = PATH + \"/data/DRIVE/training\"\n",
    "\n",
    "TEST_PATH = PATH + \"/data/DRIVE/test\"\n",
    "\n",
    "PROCESSED_TRAIN_PATH = PATH + '/data/DRIVE_preprocessed/train'\n",
    "\n",
    "PROCESSED_TEST_PATH = PATH + '/data/DRIVE_preprocessed/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(PATH + \"/data/DRIVE_preprocessed\", ignore_errors=False, onerror=None)\n",
    "os.mkdir(PATH + \"/data/DRIVE_preprocessed\")\n",
    "os.mkdir(PROCESSED_TRAIN_PATH)\n",
    "os.mkdir(PROCESSED_TEST_PATH)\n",
    "os.mkdir(PROCESSED_TRAIN_PATH + \"/images\")\n",
    "os.mkdir(PROCESSED_TRAIN_PATH + \"/labels\")\n",
    "os.mkdir(PROCESSED_TEST_PATH + \"/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimgs = len(os.listdir(TRAIN_PATH + '/images'))\n",
    "channels = 1\n",
    "height = 584\n",
    "width = 565\n",
    "\n",
    "i=1\n",
    "for file in sorted(os.listdir(TRAIN_PATH + \"/images\")):\n",
    "  img = cv2.imread(TRAIN_PATH + \"/images/\"+file, 0)\n",
    "  img = np.expand_dims(img, axis=0)\n",
    "  img = np.moveaxis(img,0, -1)\n",
    "  #print(img.shape)\n",
    "  cv2.imwrite(PROCESSED_TRAIN_PATH + \"/images/\" + str(i) + '.png',img)\n",
    "  i += 1\n",
    "\n",
    "\n",
    "i=1\n",
    "for file in sorted(os.listdir(TRAIN_PATH + \"/labels\")):\n",
    "  g_truth = Image.open(TRAIN_PATH + \"/labels/\" + file)\n",
    "  cv2.imwrite(PROCESSED_TRAIN_PATH + \"/labels/\" + str(i) + '.png', np.asarray(g_truth))\n",
    "  i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimgs = len(os.listdir(TEST_PATH + '/images'))\n",
    "channels = 1\n",
    "height = 584\n",
    "width = 565\n",
    "\n",
    "i=1\n",
    "for file in sorted(os.listdir(TEST_PATH + \"/images\")):\n",
    "  img = cv2.imread(TEST_PATH + \"/images/\"+file, 0)\n",
    "  img = np.expand_dims(img, axis=0)\n",
    "  img = np.moveaxis(img,0, -1)\n",
    "  #print(img.shape)\n",
    "  cv2.imwrite(PROCESSED_TEST_PATH + \"/images/\" + str(i) + '.png',img)\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding is done.\n",
      "Padding is done.\n",
      "Padding is done.\n"
     ]
    }
   ],
   "source": [
    "pad(PROCESSED_TRAIN_PATH + \"/images\", PROCESSED_TRAIN_PATH + \"/images\", False)\n",
    "pad(PROCESSED_TRAIN_PATH + \"/labels\", PROCESSED_TRAIN_PATH + \"/labels\", False)\n",
    "pad(PROCESSED_TEST_PATH + \"/images\", PROCESSED_TEST_PATH + \"/images\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augmentation \n",
    "\n",
    "In deep learning tasks, a lot of data is need to train DNN model, when the dataset is not big enough, data augmentation should be applied.\n",
    "\n",
    "keras.preprocessing.image.ImageDataGenerator is a data generator, which can feed the DNN with data like : (data,label), it can also do data augmentation at the same time.\n",
    "\n",
    "It is very convenient for us to use keras.preprocessing.image.ImageDataGenerator to do data augmentation by implement image rotation, shift, rescale and so on... see [keras documentation](https://keras.io/preprocessing/image/) for detail.\n",
    "\n",
    "For image segmentation tasks, the image and mask must be transformed **together!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define your data generator\n",
    "\n",
    "If you want to visualize your data augmentation result, set save_to_dir = your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you don't want to do data augmentation, set data_gen_args as an empty dict.\n",
    "data_gen_args = dict()\n",
    "\n",
    "# data_gen_args = dict(rotation_range=0.2,\n",
    "#                     width_shift_range=0.05,\n",
    "#                     height_shift_range=0.05,\n",
    "#                     shear_range=0.05,\n",
    "#                     zoom_range=0.05,\n",
    "#                     horizontal_flip=True,\n",
    "#                     fill_mode='nearest')\n",
    "myGenerator = trainGenerator(20,'data/membrane/train','image','label',data_gen_args,save_to_dir = \"data/membrane/train/aug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize your data augmentation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you will see 60 transformed images and their masks in data/membrane/train/aug\n",
    "num_batch = 3\n",
    "for i,batch in enumerate(myGenerator):\n",
    "    if(i >= num_batch):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create .npy data\n",
    "\n",
    "If your computer has enough memory, you can create npy files containing all your images and masks, and feed your DNN with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arr,mask_arr = geneTrainNpy(\"data/membrane/train/aug/\",\"data/membrane/train/aug/\")\n",
    "#np.save(\"data/image_arr.npy\",image_arr)\n",
    "#np.save(\"data/mask_arr.npy\",mask_arr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0bddfeb57c1fb75223dbf39449e882687a67de532191dbbd9d55c4d4d1df7aac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
